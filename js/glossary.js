
var tableData = [
    { "td1": "Dimensional", "td2": "" },
    { "td1": "Finetune Model", "td2": "" },
    { "td1": "flowise", "td2": "Open source UI visual tool to build your customized LLM flow using LangchainJS, written in Node Typescript/Javascript" },
    { "td1": "Foundation Model", "td2": "" },
    { "td1": "GPT", "td2": "Generative Pre-trained Transformer" },
    { "td1": "gpt4all", "td2": "A free-to-use, locally running, privacy-aware chatbot. No GPU or internet required." },
    { "td1": "Model", "td2": "AI models are like smart algorithms that learn from examples to perform tasks such as recognizing images, understanding language, or making predictions, without being explicitly programmed for each task." },
    { "td1": "ollama", "td2": "Get up and running with large language models locally." },
    { "td1": "Predict", "td2": "" },
    { "td1": "Pretrained Model", "td2": "" },
    { "td1": "Quantization", "td2": "Quantization refers to techniques for performing computations and storing tensors at lower bit widths than floating point precision" },
    { "td1": "RAG", "td2": "Retrieval Augmented Generation" },
    { "td1": "Sentiment Analysis", "td2": "" },
    { "td1": "Token", "td2": "In natural language processing and machine learning, a token is a unit of text, which could be as short as one character or as long as one word" },
    { "td1": "Tokenization", "td2": "Word Tokenization, Sub-Word Tokenization, Character Tokenization" },
];

//="{""td1"":"""&A1&""",""td2"":"""&B1&"""},"
