
var tableData = [
    { "td1": "Dimensional", "td2": "refers to the number of features or variables that are used to represent each instance of data. It relates to the complexity and richness of the dataset." },
    { "td1": "Finetune Model", "td2": "refers to the process of taking a pre-trained model and further training it on a specific task or dataset to improve its performance for that particular task." },
    { "td1": "flowise", "td2": "Open source UI visual tool to build your customized LLM flow using LangchainJS, written in Node Typescript/Javascript" },
    { "td1": "Foundation Model", "td2": "a basic model or architecture that serves as the starting point for more complex AI systems." },
    { "td1": "GPT", "td2": "Generative Pre-trained Transformer" },
    { "td1": "gpt4all", "td2": "A free-to-use, locally running, privacy-aware chatbot. No GPU or internet required." },
    { "td1": "Model", "td2": "AI models are like smart algorithms that learn from examples to perform tasks such as recognizing images, understanding language, or making predictions, without being explicitly programmed for each task." },
    { "td1": "ollama", "td2": "Get up and running with large language models locally." },
    { "td1": "Predict", "td2": "refers to the ability of a model or system to make an educated guess or estimation about future outcomes based on available data and patterns learned during training." },
    { "td1": "Pretrained Model", "td2": "in the context of artificial intelligence refers to a model that has been trained on a large dataset for a specific task or set of tasks before being made available for further use." },
    { "td1": "Quantization", "td2": "Quantization refers to techniques for performing computations and storing tensors at lower bit widths than floating point precision" },
    { "td1": "RAG", "td2": "Retrieval Augmented Generation" },
    { "td1": "Sentiment Analysis", "td2": "is a natural language processing (NLP) technique used to determine the sentiment or emotional tone expressed in a piece of text." },
    { "td1": "Token", "td2": "In natural language processing and machine learning, a token is a unit of text, which could be as short as one character or as long as one word" },
    { "td1": "Tokenization", "td2": "Word Tokenization, Sub-Word Tokenization, Character Tokenization" },
    { "td1": "LoRA", "td2": "(Low - Rank Adaptation)" },
    //{ "td1": "", "td2": "" },
    
];

//="{""td1"":"""&A1&""",""td2"":"""&B1&"""},"
